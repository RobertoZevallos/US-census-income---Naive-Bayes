{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a5f9df",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1>Data Prep for Naive Bayes</h1>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "To start our assignment, we imported the csv file and created a list to specify the headers of each column to be used in the \"name\" argument during the reading of the csv file, we gathered basic information of our data, and searched for missing values by using the .info() and .isnull().sum() methods. \n",
    "<br><br>\n",
    "The .info() function helped us check the information of our data, like validation of data types and number of columns we had on the dataset. \n",
    "The .isnull() function we used, at first showed that everything was false, meaning that we supposedly has no missing values on our data. However, we suspected that some missing values could have been codified in a different way and not as NaN or the default missing values that the read_csv method could identify. For this, we decided to create a loop to perform value_counts on each of our columns and print these values in a sorted way. By doing this, we found out that there were some question marks in the data that could have been used to mark missing values.\n",
    "<br><br>\n",
    "Further, by looking at the information we have gathered, we identified that a space was located before of every question mark representing the missing values, so we added the skipinitialspace argument and set it to True to make sure that we cleared the space before the question marks. Then, we added our \"?\" in the na_values argument among with the default values so that these could be identified as missing values in our data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1621941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf # regression modeling\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "\n",
    "\n",
    "# specifying a file \n",
    "file = \"./US Census Above 50k Predictor.csv\"\n",
    "\n",
    "#creating list of column names\n",
    "header_names = [\"Age\",\n",
    "                \"Job/occupation\",\n",
    "                \"Type of employment\",\n",
    "                \"Current hours of work/week\",\n",
    "                \"Capital gain/loss\",\n",
    "                \"Highest level of education\",\n",
    "                \"Completed years of education\",\n",
    "                \"Marital status\",\n",
    "                \"Relationship inside the household\",\n",
    "                \"Ethnicity\",\n",
    "                \"Gender\",\n",
    "                \"Country of birth\", \n",
    "                \"Income\"]\n",
    "\n",
    "# reading file into Python through pandas\n",
    "# using names to asign a string as a column name\n",
    "us_census = pd.read_csv(filepath_or_buffer  = file,\n",
    "                       sep = ',',\n",
    "                       names = header_names,\n",
    "                        #using skipininitialspace after finding out with a loop there were '?' in the values\n",
    "                       skipinitialspace = True,\n",
    "                        #converting the '?' to a NaN value\n",
    "                       na_values = ['','#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
    "                                    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
    "                                    'nan', 'null','?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c9f04",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Validation of identification of missing values</strong>\n",
    "<br>\n",
    "We checked that what we did to identify the missing values was working by using the isnull().sum() functions. We could see that now we have missing values for Job/occupation, Type of employment, and Country of birth.\n",
    "<br>\n",
    "By running the value_counts() function on these variables, we identified how many values we had on each of their categories and we were able to compare these with the amount of missing values. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for NaN values\n",
    "us_census.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census['Job/occupation'].value_counts(normalize = False,\n",
    "                                         sort      = False,\n",
    "                                         ascending = False,\n",
    "                                         dropna    = False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census['Type of employment'].value_counts(normalize = False,\n",
    "                                             sort      = False,\n",
    "                                             ascending = False,\n",
    "                                             dropna    = False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census['Country of birth'].value_counts(normalize = False,\n",
    "                                           sort      = False,\n",
    "                                           ascending = False,\n",
    "                                           dropna    = False).sort_index().round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a8578",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Flagging the missing values</strong>\n",
    "<br>\n",
    "To point out the missing values we created a loop to flag them and added new columns at the end of our dataset with \"1\" were the missing values were found. These new columns have the same name as the original column were the missing values were found, but a letter \"m\" from missing was added at the beginning.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag the missing values\n",
    "for column in us_census:\n",
    "\n",
    "    if us_census[column].isnull().astype(int).sum() > 0:\n",
    "        us_census['m_' + column] = us_census[column].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5208e593",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Describing categorical variables</strong>\n",
    "<br>\n",
    "To describe our categorical variables we used the function .describe() to help us know the number of categories on each categorical variable, how many values we could find, and the mode for each categorical variable. The argument include was used to obtain only this type of variables.\n",
    "<br><br>\n",
    "We found out that some of our variables wouldn't be the best approach to use as a dummy variables if we didn't group them into smaller categories, because they have too many categories. For example, Country of birth had 41 possible values.\n",
    "<br><br>\n",
    "We also used the value_counts() method with a for loop to identify the frequency of each categorical value, because later on we would need this as an input to create smaller categories among our variables. It is important to mention that this cell of code was commented out so that it is not run unless someone needs to look at the frequencies again.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14194a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing categorical variables\n",
    "us_census.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finding frequency for each categorical values\n",
    "\n",
    "# for col in us_census.select_dtypes(include = 'object'):\n",
    "#     count_values_columns = us_census[col].value_counts(normalize = True,\n",
    "#                                                        sort      = True,\n",
    "#                                                        ascending = True).round(decimals = 2)\n",
    "#     print(count_values_columns)\n",
    "#     print('-'*90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338d0c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<strong>Creating a separate DataFrame for our target variable</strong>\n",
    "<br>\n",
    "To be sure that we have our target variable in a separate DataFrame for future reference we decided to separate it and name it \"y\".\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886a3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a new DataFrame for Income, our target variable\n",
    "y= pd.DataFrame(data = us_census, columns = ['Income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc22d8d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<strong>Treatment of missing values</strong>\n",
    "<br>\n",
    "To treat the missing values we first created a new DataFrame were we dropped the missing values. This was done so that we could created a variable to identify the mode of this data set and to compare our new data once we imputed the missing values.\n",
    "<br><br>\n",
    "By using value_counts on our columns that had missing values, and sorting them to have the most repeated value or mode at the top, and then calling for the index 0, we were able to identify the mode. This value was saved into a new variable that would be used in the imputation process.\n",
    "<br><br>\n",
    "However, for the count of the values of Job/occupation, we decided to use the second most repeated occupation by calling the index 1. We did this because we found out that the mode was 'Prof-specialty' and this value was going to be imputed to observations which actually wouldn't have enough years of education to be lawfully allowed to work as a professional specialty. Moreover, the second most repeated value of 'Exec-managerial' is not restricted by law regarding the number of years of education required.\n",
    "<br>\n",
    "For our other missing values of Type of employment and Country of birth, the mode did make sense so we didn't need to modify our index.\n",
    "<br><br>\n",
    "Further, by using .fillna(), we were able to impute the missing values with the mode or second most repeated value. Also, we validated each imputation to make sure which value was used for the imputation.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the missing values and creating a new DataFrame\n",
    "census_dropped = pd.DataFrame.copy(us_census)\n",
    "\n",
    "census_dropped = census_dropped.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values for Job/occupation\n",
    "job_mode = us_census['Job/occupation'].value_counts(normalize = False,\n",
    "                                    sort      = True,\n",
    "                                    ascending = False).index[1]\n",
    "\n",
    "# fill NA with mode\n",
    "us_census['Job/occupation'].fillna(value = str(job_mode), #value for filling the NA\n",
    "                                   inplace = True) #replacing the Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values for Type of employment\n",
    "employment_mode = us_census['Type of employment'].value_counts(normalize = False,\n",
    "                                    sort      = True,\n",
    "                                    ascending = False).index[0]\n",
    "\n",
    "# fill NA with mode\n",
    "us_census['Type of employment'].fillna(value = str(employment_mode), #value for filling the NA\n",
    "                                   inplace = True) #replacing the Na\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12734413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values for Country of birth\n",
    "country_mode = us_census['Country of birth'].value_counts(normalize = False,\n",
    "                                    sort      = True,\n",
    "                                    ascending = False).index[0]\n",
    "\n",
    "# fill NA with mode\n",
    "us_census['Country of birth'].fillna(value = str(country_mode), #value for filling the NA\n",
    "                                   inplace = True) #replacing the Na\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6962b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating the missing values were filled with the second most repeated value\n",
    "us_census.loc[ : , ['m_Job/occupation','Job/occupation']] [us_census.loc[ : , 'm_Job/occupation'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating the missing values are filled with the mode\n",
    "us_census.loc[ : , ['m_Type of employment','Type of employment']] [us_census.loc[ : , 'm_Type of employment'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating the missing values are filled with the mode\n",
    "us_census.loc[ : , ['m_Country of birth','Country of birth']] [us_census.loc[ : , 'm_Country of birth'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation to make sure that we don't have missing values in our imputed data\n",
    "print(census_dropped.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be41b53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<strong>Validation of the treatment applied to missing values</strong>\n",
    "<br>\n",
    "To compare our original data with the imputed data we created 3 histograms including both distributions in the same graph.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8beda",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<em><strong>Distribution of Job/occupation</strong></em>\n",
    "<br>\n",
    "By looking at the graph, we found out that for the Job/occupation we did create a spike in the Exec-managerial frequency when there actually wasn't a big difference in the original data. However, we're satisfied with this imputation because as mentioned before, this occupation doesn't necessarily require a certain number of years of education, and so this could be the way to achieve the most minor disruption from the original data.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55015b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay the original and imputed distributions for Job/occupation\n",
    "fig, ax = plt.subplots(figsize = [20, 10],\n",
    "                      sharex = True, #sharing x axis between visualization\n",
    "                      sharey = True) #sharing y axis between visualization\n",
    "\n",
    "# histogram for Job/occupation - oringal data\n",
    "sns.histplot(data  = census_dropped,\n",
    "             x     = 'Job/occupation',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # drawing theoretical distribution\n",
    "             color = 'red')\n",
    "\n",
    "\n",
    "# histogram for Job/occupation - imputed data\n",
    "sns.histplot(data  = us_census,\n",
    "             x     = 'Job/occupation',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # drawing theoretical distribution\n",
    "             color = 'black')\n",
    "\n",
    "\n",
    "# titles, labels, and formatting\n",
    "plt.title(label   = \"Distribution of Job/occupation\")\n",
    "plt.xlabel(xlabel = 'Job/occupation')\n",
    "plt.ylabel(ylabel = 'Frequency')\n",
    "plt.xlim(-0.5, 14) # setting x-axis range\n",
    "plt.ylim(0.0, 5000) # setting y-axis range\n",
    "\n",
    "\n",
    "# adds legend\n",
    "plt.legend(labels =  ['original distribution',\n",
    "                      'imputed distribution'])\n",
    "\n",
    "# compile and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bda173",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<em><strong>Distribution of Type of employment</strong></em>\n",
    "<br>\n",
    "For the type of employment, by looking at our graph we can see the private jobs were increased by our imputation. However, we already had a big difference in the frequency of this type of employment in the original data when compared to the others. So, we take this imputation the best to reduce the interference of the original information. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay the original and imputed distributions for Type of employment\n",
    "fig, ax = plt.subplots(figsize = [20, 10],\n",
    "                      sharex = True, #sharing x axis between visualization\n",
    "                      sharey = True) #sharing y axis between visualization\n",
    "\n",
    "# histogram for Type of employment - oringal data\n",
    "sns.histplot(data  = census_dropped,\n",
    "             x     = 'Type of employment',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # drawing theoretical distribution\n",
    "             color = 'red')\n",
    "\n",
    "# histogram for Type of employment - imputed data\n",
    "sns.histplot(data  = us_census,\n",
    "             x     = 'Type of employment',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # drawing theoretical distribution\n",
    "             color = 'black')\n",
    "\n",
    "\n",
    "# titles, labels, and formatting\n",
    "plt.title(label   = \"Distribution of type of employment\")\n",
    "plt.xlabel(xlabel = 'Type of employment')\n",
    "plt.ylabel(ylabel = 'Frequency')\n",
    "plt.xlim(-0.5, 7.5) # setting x-axis range\n",
    "plt.ylim(0.0, 20000) # setting y-axis range\n",
    "\n",
    "\n",
    "# adds legend\n",
    "plt.legend(labels =  ['original distribution',\n",
    "                      'imputed distribution'])\n",
    "\n",
    "# compile and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76fdd9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<em><strong>Distribution of Country of birth</strong></em>\n",
    "<br>\n",
    "For the country of birth, the histogram shows that the imputation of the United States as the country of birth increases the difference among the number of observations from this country versus the others. However, this increase makes sense because the data came from the census of the US population so we would expect this country with a vast majority of observations.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a276e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay the original and imputed distributions for Country of birth\n",
    "fig, ax = plt.subplots(figsize = [20, 10],\n",
    "                      sharex = True, #sharing x axis between visualization\n",
    "                      sharey = True) #sharing y axis between visualization\n",
    "\n",
    "# histogram for Country of birth - oringal data\n",
    "sns.histplot(data  = census_dropped,\n",
    "             x     = 'Country of birth',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # drawing theoretical distribution\n",
    "             color = 'red')\n",
    "\n",
    "# histogram for Country of birth - imputed data\n",
    "sns.histplot(data  = us_census,\n",
    "             x     = 'Country of birth',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # drawing theoretical distribution\n",
    "             color = 'black')\n",
    "\n",
    "\n",
    "# titles, labels, and formatting\n",
    "plt.title(label   = \"Distribution of Country of birth\")\n",
    "plt.xlabel(xlabel = 'Country of birth')\n",
    "plt.ylabel(ylabel = 'Frequency')\n",
    "plt.xlim(0.0, 20) # setting x-axis range\n",
    "plt.ylim(0.0, 25000) # setting y-axis range\n",
    "\n",
    "\n",
    "# adds legend\n",
    "plt.legend(labels =  ['original distribution',\n",
    "                      'imputed distribution'])\n",
    "\n",
    "# compile and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76a0cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<strong>Categorizing variables</strong>\n",
    "<br>\n",
    "As mentioned before, since all of our variables had too many categories or values, and getting dummy variables for all of them will significantly reduce our degrees of freedom, and create stratas with not enough observations, we decided to group them based on their similar characteristics.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95463ab4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<em><strong>Grouping non categorical variables</strong></em>\n",
    "<br>\n",
    "First used a loop to group all of our non categorical variables into predetermined bins, and create a new column where the resulting bins will be identified regarding the original data.\n",
    "<br>\n",
    "<em>-Age: </em>Grouped by using descriptive statistics and quartiles.\n",
    "<br>\n",
    "<em>-Current hours of work/week: </em>Grouped by looking at job descriptions in the US.\n",
    "<br>\n",
    "<em>-Capital gain/loss: </em>Grouped by creating groups of negative vs positive, and dividing the positive in groups of 5K.\n",
    "<br>\n",
    "<em>-Completed years of education: </em>Grouped by education levels for the US.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ab706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating categories for non categorical variables \n",
    "\n",
    "#copying into a new dataframe so that the original imputated data is not modified\n",
    "us_census2 = us_census.copy()\n",
    "\n",
    "# variable Age\n",
    "us_census2 ['Cat_Age'] = 0\n",
    "\n",
    "# for loop with iterrows()\n",
    "for index, col in us_census2.iterrows():\n",
    "    \n",
    "    \n",
    "    # conditionals to change the values in the new column, defined by looking at descriptive statistics\n",
    "    if us_census2.loc[index, 'Age'] < 28:\n",
    "        us_census2.loc[index, 'Cat_Age'] = '[0 - 28)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Age'] < 37:\n",
    "        us_census2.loc[index, 'Cat_Age'] = '[28 - 37)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Age'] < 48:\n",
    "        us_census2.loc[index, 'Cat_Age'] = '[37 - 48)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Age'] <= 90:\n",
    "        us_census2.loc[index, 'Cat_Age'] = '[48 - 90)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Age'] >= 91:\n",
    "        us_census2.loc[index, 'Cat_Age'] = '[91 - inf)'\n",
    "    \n",
    "    \n",
    "    # safety net\n",
    "    else:\n",
    "        us_census2.loc[index, 'Cat_Age'] = 'Age not defined'\n",
    "        \n",
    "\n",
    "# variable Current hours of work/week\n",
    "us_census2 ['Cat_Current hours of work/week'] = 0\n",
    "\n",
    "# for loop with iterrows()\n",
    "for index, col in us_census2.iterrows():\n",
    "    \n",
    "    \n",
    "    # conditionals to change the values in the new column, defined by looking at job descriptions for the US\n",
    "    if us_census2.loc[index, 'Current hours of work/week'] < 20:\n",
    "        us_census2.loc[index, 'Cat_Current hours of work/week'] = 'Half time [0 - 20)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Current hours of work/week'] < 30:\n",
    "        us_census2.loc[index, 'Cat_Current hours of work/week'] = 'Part time [20 - 30)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Current hours of work/week'] < 41:\n",
    "        us_census2.loc[index, 'Cat_Current hours of work/week'] = 'Full time [30 - 41)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Current hours of work/week'] < 61:\n",
    "        us_census2.loc[index, 'Cat_Current hours of work/week'] = 'Over time [41 - 61)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Current hours of work/week'] >= 61:\n",
    "        us_census2.loc[index, 'Cat_Current hours of work/week'] = 'Over time [61 - inf)'\n",
    "    \n",
    "    \n",
    "    # safety net\n",
    "    else:\n",
    "        us_census2.loc[index, 'Cat_Current hours of work/week'] = 'Hours not defined'\n",
    "\n",
    "\n",
    "# variable Capital gain/loss\n",
    "us_census2 ['Cat_Capital gain/loss'] = 0\n",
    "\n",
    "# for loop with iterrows()\n",
    "for index, col in us_census2.iterrows():\n",
    "    \n",
    "    \n",
    "    # conditionals to change the values in the new column\n",
    "    if us_census2.loc[index, 'Capital gain/loss'] < 0:\n",
    "        us_census2.loc[index, 'Cat_Capital gain/loss'] = 'Negative [below 0 - 0)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Capital gain/loss'] < 5000:\n",
    "        us_census2.loc[index, 'Cat_Capital gain/loss'] = '[0 - 5K)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Capital gain/loss'] < 10000:\n",
    "        us_census2.loc[index, 'Cat_Capital gain/loss'] = '[5K - 10K)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Capital gain/loss'] >= 10000:\n",
    "        us_census2.loc[index, 'Cat_Capital gain/loss'] = '[Over 10K]'\n",
    "    \n",
    "    \n",
    "    # safety net\n",
    "    else:\n",
    "        us_census2.loc[index, 'Cat_Capital gain/loss'] = 'Capital gain/loss not defined'\n",
    "\n",
    "\n",
    "# variable Completed years of education\n",
    "us_census2 ['Cat_Completed years of education'] = 0\n",
    "\n",
    "# for loop with iterrows()\n",
    "for index, col in us_census2.iterrows():\n",
    "    \n",
    "    \n",
    "    # conditionals to change the values in the new column, defined by education levels for the US\n",
    "    if us_census2.loc[index, 'Completed years of education'] < 10:\n",
    "        us_census2.loc[index, 'Cat_Completed years of education'] = 'Pre-school_K-12 [1 - 10)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Completed years of education'] == 10:\n",
    "        us_census2.loc[index, 'Cat_Completed years of education'] = 'Some-college [10]'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Completed years of education'] < 13:\n",
    "        us_census2.loc[index, 'Cat_Completed years of education'] = 'Associate [11 - 13)'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Completed years of education'] == 13:\n",
    "        us_census2.loc[index, 'Cat_Completed years of education'] = 'Undergrad [13]'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Completed years of education'] < 16:\n",
    "        us_census2.loc[index, 'Cat_Completed years of education'] = 'Masters_prof school [14 - 16)'\n",
    "        \n",
    "                \n",
    "    elif us_census2.loc[index, 'Completed years of education'] >= 16:\n",
    "        us_census2.loc[index, 'Cat_Completed years of education'] = 'Doctorate [16 - inf)'\n",
    "    \n",
    "    \n",
    "    # safety net\n",
    "    else:\n",
    "        us_census2.loc[index, 'Cat_Completed years of education'] = 'Completed years of education not defined'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95f268",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>\n",
    "<em><strong>Grouping categorical variables</strong></em>\n",
    "<br>\n",
    "Then we used a loop to group all of our categorical variables into predetermined bins, and create a new column where the resulting bins will be identified regarding the original data.\n",
    "<br>\n",
    "<em>-Job/occupation: </em>Grouped by the Standard Occupational Classification System.\n",
    "<br>\n",
    "<em>-Type of employment: </em>Grouped by private, public or (self or not employed).\n",
    "<br>\n",
    "<em>-Highest level of education: </em>Grouped by education levels for the US.\n",
    "<br>\n",
    "<em>-Martial status: </em>Grouped by currently married or not.\n",
    "<br>\n",
    "<em>-Relationship inside household: </em>Grouped by being a relative or not.\n",
    "<br>\n",
    "<em>-Ethnicity: </em>Grouped by black, white or other.\n",
    "<br>\n",
    "<em>-Country of birth: </em>Grouped by US vs others.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63074305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating categories for categorical variables\n",
    "\n",
    "# variable Job/occupation, defined by the Standard Occupational Classification System\n",
    "us_census2['Cat_Job/occupation'] = us_census2['Job/occupation'].map(\n",
    "                        {'Exec-managerial'     : 'Managerial',\n",
    "                         'Prof-specialty'      : 'Professional',\n",
    "                         'Craft-repair '       : 'Operational',\n",
    "                         'Adm-clerical'        : 'Operational',\n",
    "                         'Sales'               : 'Operational',\n",
    "                         'Other-service'       : 'Operational',\n",
    "                         'Machine-op-inspct'   : 'Operational',\n",
    "                         'Transport-moving'    : 'Operational',\n",
    "                         'Handlers-cleaners'   : 'Operational',\n",
    "                         'Farming-fishing'     : 'Operational',\n",
    "                         'Tech-support'        : 'Operational',\n",
    "                         'Protective-serv'     : 'Operational',\n",
    "                         'Priv-house-serv '    : 'Operational',\n",
    "                         'Armed-Forces'        : 'Operational'})\n",
    "\n",
    "\n",
    "# variable Type of employment, defined by private, public or (self or not employed)\n",
    "us_census2['Cat_Type of employment'] = us_census2['Type of employment'].map(\n",
    "                        {'Never-worked'     : 'Self or not employed',\n",
    "                         'Without-pay'      : 'Self or not employed',\n",
    "                         'Local-gov'        : 'Government-public',\n",
    "                         'State-gov'        : 'Government-public',\n",
    "                         'Federal-gov'      : 'Government-public',\n",
    "                         'Private'          : 'Private',\n",
    "                         'Self-emp-not-inc' : 'Self or not employed',\n",
    "                         'Self-emp-inc'     : 'Self or not employed'})\n",
    "\n",
    "\n",
    "# variable Highest level of education, defined by education levels for the US\n",
    "us_census2['Cat_Highest level of education'] = us_census2['Highest level of education'].map(\n",
    "                        {'Preschool'   : 'Pre-school_K-12',\n",
    "                         '1st-4th'     : 'Pre-school_K-12',\n",
    "                         '5th-6th'     : 'Pre-school_K-12',\n",
    "                         '7th-8th'     : 'Pre-school_K-12',\n",
    "                         '9th'         : 'Pre-school_K-12',\n",
    "                         '10th'        : 'Pre-school_K-12',\n",
    "                         '11th'        : 'Pre-school_K-12',\n",
    "                         '12th'        : 'Pre-school_K-12',\n",
    "                         'HS-grad'     : 'Pre-school_K-12',\n",
    "                         'Some-college': 'Some-college',\n",
    "                         'Assoc-voc'   : 'Associate',\n",
    "                         'Assoc-acdm'  : 'Associate',\n",
    "                         'Bachelors'   : 'Undergrad',\n",
    "                         'Masters'     : 'Grad_masters_prof_sch', \n",
    "                         'Prof-school' : 'Grad_masters_prof_sch',\n",
    "                         'Doctorate'   : 'Grad_doctorate'})\n",
    "\n",
    "# variable Marital status, defined by currently married or not\n",
    "us_census2['Cat_Marital status'] = us_census2['Marital status'].map(\n",
    "                        {'Married-civ-spouse'    : 'Married',\n",
    "                         'Married-AF-spouse'     : 'Married',\n",
    "                         'Married-spouse-absent' : 'Married',\n",
    "                         'Divorced'              : 'Not married',\n",
    "                         'Separated'             : 'Not married',\n",
    "                         'Widowed'               : 'Not married',\n",
    "                         'Never-married'         : 'Not married'})\n",
    "\n",
    "# variable Relationship inside the household, defined by being a relative or not\n",
    "us_census2['Cat_Relationship inside the household'] = us_census2['Relationship inside the household'].map(\n",
    "                        {'Not-in-family'  : 'Not_related',\n",
    "                         'Husband'        : 'Related',\n",
    "                         'Wife'           : 'Related',\n",
    "                         'Own-child'      : 'Related',\n",
    "                         'Unmarried'      : 'Related',\n",
    "                         'Other-relative' : 'Related'})\n",
    "\n",
    "# variable Ethnicity, defined by black, white or other\n",
    "us_census2['Cat_Ethnicity'] = us_census2['Ethnicity'].map(\n",
    "                        {'Black'              : 'Black',\n",
    "                         'White'              : 'White',\n",
    "                         'Asian-Pac-Islander' : 'Other ethnicity',\n",
    "                         'Amer-Indian-Eskimo' : 'Other ethnicity',\n",
    "                         'Other'              : 'Other ethnicity'})\n",
    "\n",
    "# variable Country of birth, defined by US vs others.\n",
    "for index, col in us_census2.iterrows():\n",
    "    \n",
    "    # conditionals to change the values in the new column, defined by  US or others\n",
    "    if us_census2.loc[index, 'Country of birth'] == 'United-States':\n",
    "        us_census2.loc[index, 'Cat_Country of birth'] = 'USA'\n",
    "        \n",
    "        \n",
    "    elif us_census2.loc[index, 'Country of birth'] != 'United-States':\n",
    "        us_census2.loc[index, 'Cat_Country of birth'] = 'Other'\n",
    "        \n",
    "           # safety net\n",
    "    else:\n",
    "        us_census2.loc[index, 'Cat_Country of birth'] = 'Country of birth not defined'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61553a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>\n",
    "<em><strong>Printing the results for the grouping</strong></em>\n",
    "<br>\n",
    "Print statements were used with value counts for each new column containing the defined bins. This helped us identify that our division did not create stratas with too little observations and so the analysis could continue.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f550e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the value counts for each category\n",
    "print(us_census2['Cat_Age'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Job/occupation'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Type of employment'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Current hours of work/week'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Capital gain/loss'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Highest level of education'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Completed years of education'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Marital status'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Relationship inside the household'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Ethnicity'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Gender'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Cat_Country of birth'].value_counts())\n",
    "print('-'*70)\n",
    "print(us_census2['Income'].value_counts())\n",
    "print('-'*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed22603",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<strong>Getting dummy variables for the new categories</strong>\n",
    "<br>\n",
    "We created a DataFrame containing the dummy variables generated by using the get_dummies() function. This function was applied to the new categories created in the previous steps and the variables Gender and Income which didn't required any categorization because only two possible values already existed for these variables.\n",
    "<br><br>\n",
    "Additionally, since this new DataFrame duplicated the original columns for which we created the categories, we decided to drop them and generate a \"cleaned\" DataFrame containing no duplicate columns.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbbbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all dummies\n",
    "us_census2_dummies = pd.get_dummies(data       = us_census2, \n",
    "                                    columns    = ['Cat_Age',\n",
    "                                                  'Cat_Job/occupation',\n",
    "                                                  'Cat_Type of employment',\n",
    "                                                  'Cat_Current hours of work/week',\n",
    "                                                  'Cat_Capital gain/loss',\n",
    "                                                  'Cat_Highest level of education',\n",
    "                                                  'Cat_Completed years of education',\n",
    "                                                  'Cat_Marital status',\n",
    "                                                  'Cat_Relationship inside the household',\n",
    "                                                  'Cat_Ethnicity',\n",
    "                                                  'Gender',\n",
    "                                                  'Cat_Country of birth',\n",
    "                                                  'Income'])\n",
    "\n",
    "#dropping repeated columns\n",
    "us_census2_cleaned = us_census2_dummies.drop([\"Age\",\n",
    "                                      \"Job/occupation\",\n",
    "                                      \"Type of employment\",\n",
    "                                      \"Current hours of work/week\",\n",
    "                                      \"Capital gain/loss\",\n",
    "                                      \"Highest level of education\",\n",
    "                                      \"Completed years of education\",\n",
    "                                      \"Marital status\",\n",
    "                                      \"Relationship inside the household\",\n",
    "                                      \"Ethnicity\",\n",
    "                                     # \"Gender\",\n",
    "                                      \"Country of birth\", \n",
    "                                      #\"Income\",\n",
    "                                      \"m_Job/occupation\",\n",
    "                                      \"m_Type of employment\",\n",
    "                                      \"m_Country of birth\"],\n",
    "                                       axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b01fc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<strong>Concatenating the dummy variables with imputed data</strong>\n",
    "<br>\n",
    "Succeeding the generation of the dummy variables, we added them with the concatenate function to our imputed dataset.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10752920",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census3 = pd.concat([us_census, us_census2_cleaned], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a66bda",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<strong>Generating training and testing sets</strong>\n",
    "<br>\n",
    "Afterwards we split the data into training and testing sets for both our features and the dependent variable by taking 20% of the total records to be allocated as our testing set, this percentage was selected randomly. We did set a random seed so that we will always have the same selection if we decided to change our model. \n",
    "<br>\n",
    "The X or features and Y or dependent variables training sets were concatenated into one single dataset, we did the same for X and Y testing sets.\n",
    "<br><br>\n",
    "Next, these two datasets were exported and saved as Excel files to be used in out Naive Bayes model.\n",
    "<br>\n",
    "It is important to clarify that we decided to drop every variable that was not a dummy variable from our data sets. This was done so that these wouldn't be exported as part of our Excel files because we won't be using these original columns in our analysis. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42255d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing explanatory variable data, dropping columns and dependent variable\n",
    "us_census3_data = us_census3.drop(['Age',\n",
    "                                   'Job/occupation',\n",
    "                                   'Type of employment',\n",
    "                                   'Current hours of work/week',\n",
    "                                   'Capital gain/loss',\n",
    "                                   'Highest level of education',\n",
    "                                   'Completed years of education',\n",
    "                                   'Marital status',\n",
    "                                   'Relationship inside the household',\n",
    "                                   'Ethnicity',\n",
    "                                   'Gender',\n",
    "                                   'Country of birth',\n",
    "                                   'Income',\n",
    "                                   'm_Job/occupation',\n",
    "                                   'm_Type of employment',\n",
    "                                   'm_Country of birth',\n",
    "                                   'Income_<=50K',\n",
    "                                   'Income_>50K',\n",
    "                                   'Cat_Age_[0 - 28)',\n",
    "                                   'Cat_Job/occupation_Managerial',\n",
    "                                   'Cat_Type of employment_Government-public',\n",
    "                                   'Cat_Current hours of work/week_Full time [30 - 41)',\n",
    "                                   'Cat_Capital gain/loss_Negative [below 0 - 0)',\n",
    "                                   'Cat_Highest level of education_Associate',\n",
    "                                   'Cat_Completed years of education_Associate [11 - 13)',\n",
    "                                   'Cat_Marital status_Married',\n",
    "                                   'Cat_Relationship inside the household_Not_related',\n",
    "                                   'Cat_Ethnicity_Black',\n",
    "                                   'Gender_Female',\n",
    "                                   'Cat_Country of birth_Other'],\n",
    "                                    axis = 1)\n",
    "\n",
    "# preparing response variable data\n",
    "us_census3_target = us_census3.loc[ : , ['Income_<=50K','Income_>50K']]\n",
    "\n",
    "# preparing training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            us_census3_data,\n",
    "            us_census3_target,\n",
    "            test_size = 0.20,\n",
    "            random_state = 1223)\n",
    "\n",
    "\n",
    "# printing to validate the size of our sets\n",
    "print(f\"\"\"\n",
    "Training Data \n",
    "-------------\n",
    "X-side: {x_train.shape}\n",
    "y-side: {y_train.shape[0]}\n",
    "\n",
    "\n",
    "Testing Data\n",
    "------------\n",
    "X-side: {x_test.shape}\n",
    "y-side: {y_test.shape[0]}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging x_train and y_train so that they can be used in statsmodels\n",
    "us_census3_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "# merging x_test and y_test so that they can be used in statsmodels\n",
    "us_census3_test = pd.concat([x_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saving the training set as an Excel file\n",
    "# us_census3_train.to_excel(excel_writer = \"us_census_train.xlsx\",\n",
    "#                         index        = False)\n",
    "\n",
    "# # saving the testing set as an Excel file\n",
    "# us_census3_test.to_excel(excel_writer = \"us_census_test.xlsx\",\n",
    "#                        index        = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
